{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from natsort import natsorted\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from monai.transforms import AffineGrid\n",
    "from math import pi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/aaron/Dropbox/KCL/Tools/CustomScripts')\n",
    "from calculate_dice import get_dice\n",
    "\n",
    "from labelmergeandsplit.labelreg_utils import get_coms, get_covs, affine_transform_image, optimize_affine_labelreg, \\\n",
    "    affine_transform_influence_regions\n",
    "from labelmergeandsplit.merging_utils import get_merged_label_dataframe, merge_label_volumes, map_labels_in_volume\n",
    "from labelmergeandsplit.splitting_utils import get_fuzzy_prior_fudged, split_merged_labels_paths, split_merged_label, \\\n",
    "    get_influence_regions\n",
    "from utils.plot_matrix_slices import plot_matrix_slices\n",
    "\n",
    "from config.config import PROJ_ROOT\n",
    "from skimage.measure import label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:42:13.695302Z",
     "start_time": "2024-07-30T14:42:09.572314Z"
    }
   },
   "id": "a2220f9ca56cb9a",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# set the random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "def get_random_affine(img_shape):\n",
    "    shape = img_shape\n",
    "\n",
    "    # example affine matrix\n",
    "    # shift to image center\n",
    "    R_origin_to_center = np.array([\n",
    "        [1, 0, 0, -shape[0] / 2],\n",
    "        [0, 1, 0, -shape[1] / 2],\n",
    "        [0, 0, 1, -shape[2] / 2],\n",
    "        [0, 0, 0, 1],\n",
    "    ])\n",
    "\n",
    "    affineGrid = AffineGrid(\n",
    "        rotate_params=[pi / 3, pi / 5, pi / 2],  # Sequence[float] | float | None = None,\n",
    "        shear_params=[0.1] * 6,  # Sequence[float] | float | None = None,\n",
    "        translate_params=[-0, -0, 0],  # Sequence[float] | float | None = None,\n",
    "        scale_params=None,  # Sequence[float] | float | None = None,\n",
    "        device='cpu',  # np.device | None = None,\n",
    "        dtype=np.float32,  # DtypeLike = np.float32,\n",
    "        align_corners=False,  # bool = False,\n",
    "        affine=None,  # NdarrayOrTensor | None = None,\n",
    "        lazy=False,  # bool = False,\n",
    "    )\n",
    "    _, R_rot = affineGrid(spatial_size=(64, 64, 64))\n",
    "    R_rot = R_rot.cpu().numpy()\n",
    "\n",
    "    # shift back to original position\n",
    "    R_origin_to_corner = np.array([\n",
    "        [1, 0, 0, shape[0] / 2],\n",
    "        [0, 1, 0, shape[1] / 2],\n",
    "        [0, 0, 1, shape[2] / 2],\n",
    "        [0, 0, 0, 1],\n",
    "    ])\n",
    "\n",
    "    R = R_origin_to_corner @ R_rot @ R_origin_to_center\n",
    "\n",
    "    return R\n",
    "\n",
    "\n",
    "def get_network_output_from_registered_image(label_path_unmerged, pad):\n",
    "    # load an original label image\n",
    "    label_nii_unmerged = nib.load(label_path_unmerged)\n",
    "    label_data_unmerged = label_nii_unmerged.get_fdata()\n",
    "\n",
    "    # pad the label image to avoid cropping of foreground after transformation\n",
    "    label_data_unmerged = np.pad(label_data_unmerged, pad, mode='constant', )\n",
    "\n",
    "    # merge the labels\n",
    "    label_data_merged = map_labels_in_volume(label_data_unmerged, label_to_merged_label_mapping)\n",
    "\n",
    "    # get an example affine that represents the ground truth transformation (to be estimated)\n",
    "    R_grtr = get_random_affine(label_data_unmerged.shape)\n",
    "    # R_grtr = np.diag([1, 1, 1, 1])\n",
    "\n",
    "    # transform the label image\n",
    "    transformed_label_unmerged = torch.tensor(\n",
    "        affine_transform_image(torch.tensor(label_data_unmerged), torch.tensor(np.linalg.inv(R_grtr))))\n",
    "\n",
    "    # put on GPU\n",
    "    transformed_label_unmerged = transformed_label_unmerged.to(\"cuda\")\n",
    "\n",
    "    # merge the labels\n",
    "    transformed_label_merged = map_labels_in_volume(transformed_label_unmerged, label_to_merged_label_mapping)\n",
    "\n",
    "    return transformed_label_merged, transformed_label_unmerged, label_data_merged, R_grtr\n",
    "\n",
    "\n",
    "def plot_results(image_title_pairs):\n",
    "    # plot the images\n",
    "    fig, axes = plt.subplots(1, len(image_title_pairs), figsize=(3 * len(image_title_pairs), 6))\n",
    "\n",
    "    for i, (image, title) in enumerate(image_title_pairs):\n",
    "        image = image.cpu().numpy() if isinstance(image, torch.Tensor) else image\n",
    "        axes[i].imshow(image[:, :, image.shape[2] // 2])\n",
    "        axes[i].set_title(title)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:42:13.705657Z",
     "start_time": "2024-07-30T14:42:13.696715Z"
    }
   },
   "id": "2ef636b600264fb6",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaron/Dropbox/KCL/Projects/label_merge_and_split/labelmergeandsplit/merging_utils.py:502: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label_data = torch.tensor(label_data, device=\"cuda\")\n"
     ]
    }
   ],
   "source": [
    "# label support is needed to get the influence regions\n",
    "label_support_path = '/mnt/dgx-server/projects2023/dynunet_pipeline_label_merging_from_label_support/data/tasks/task3061_mindaomic/models/merged_model/fold0/label_merging/label_support.pt.npz'\n",
    "# reference label image\n",
    "label_path_ref = '/mnt/dgx-server/projects2023/dynunet_pipeline_label_merging_from_label_support/data/tasks/task3061_mindaomic/input/dataset/labelsTr/mindaomic_0002.nii.gz'\n",
    "#label_path_ref = '/mnt/dgx-server/projects2023/dynunet_pipeline_label_merging_from_label_support/data/tasks/task3061_mindaomic/results/inference/merged_model/fold0/mindaomic_0005.nii.gz'\n",
    "# ground truth label image\n",
    "#label_path_unmerged = '/mnt/dgx-server/projects2023/dynunet_pipeline_label_merging_from_label_support/data/tasks/task3061_mindaomic/input/dataset/labelsTr/mindaomic_0002.nii.gz'\n",
    "label_path_unmerged = '/mnt/dgx-server/projects2023/dynunet_pipeline_label_merging_from_label_support/data/tasks/task3061_mindaomic/results/inference/merged_model/fold0/mindaomic_0005.nii.gz'\n",
    "# read label to merged label mapping\n",
    "merged_labels_csv_path = '/mnt/dgx-server/projects2023/dynunet_pipeline_label_merging_from_label_support/data/tasks/task3061_mindaomic/models/merged_model/fold0/label_merging/merged_labels.csv'\n",
    "\n",
    "\n",
    "# # label support is needed to get the influence regions\n",
    "# label_support_path = os.path.join(PROJ_ROOT, 'data', 'task2153_mind', 'output', 'label_support.pt.npz')\n",
    "# # reference label image\n",
    "# label_path_ref = os.path.join(PROJ_ROOT, 'data', 'task2153_mind', 'input', 'dataset', 'labelsTr', 'mind_000.nii.gz')\n",
    "# # ground truth label image\n",
    "# label_path_unmerged = os.path.join(PROJ_ROOT, 'data', 'task2153_mind', 'input', 'dataset', 'labelsTs', 'mind_038.nii.gz')\n",
    "# label_path_unmerged = os.path.join(PROJ_ROOT, 'data', 'task2153_mind', 'input', 'dataset', 'labelsTr', 'mind_002.nii.gz')\n",
    "# # read label to merged label mapping\n",
    "# merged_labels_csv_path = os.path.join(PROJ_ROOT, 'data', 'task2153_mind', 'output', 'merged_labels.csv')\n",
    "\n",
    "\n",
    "channel_to_label_mapping = pd.read_csv(merged_labels_csv_path, index_col='channel').to_dict()['merged_label']\n",
    "merged_labels_df = pd.read_csv(merged_labels_csv_path, index_col='label')\n",
    "label_to_merged_label_mapping = merged_labels_df['merged_label'].to_dict()\n",
    "\n",
    "\n",
    "pad = 10\n",
    "\n",
    "# perturb the ground truth label image with an affine transformation\n",
    "transformed_label_merged, split_label_grtr, label_data_merged_mni, R = (\n",
    "    get_network_output_from_registered_image(label_path_unmerged, pad))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:42:14.624834Z",
     "start_time": "2024-07-30T14:42:13.706621Z"
    }
   },
   "id": "1cd923a4bf27c203",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([213, 249, 213])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_label_merged.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:42:22.460852Z",
     "start_time": "2024-07-30T14:42:22.457385Z"
    }
   },
   "id": "11c182c6c63ae040",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[[0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         ...,\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0]],\n \n        [[0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         ...,\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0]],\n \n        [[0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         ...,\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0]],\n \n        ...,\n \n        [[0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         ...,\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0]],\n \n        [[0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         ...,\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0]],\n \n        [[0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         ...,\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0],\n         [0, 0, 0, ..., 0, 0, 0]]]),\n 183)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label(transformed_label_merged.cpu().numpy(), return_num=True, connectivity=3, background=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:45:56.923471Z",
     "start_time": "2024-07-30T14:45:56.634582Z"
    }
   },
   "id": "65fa79e0dba645b8",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "38d100ca6870b43f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
